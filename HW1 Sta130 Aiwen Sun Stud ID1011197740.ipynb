{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8073260",
   "metadata": {},
   "source": [
    "1. Pick one of the datasets from the ChatBot session(s) of the TUT demo (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128267e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422a807",
   "metadata": {},
   "source": [
    "2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a pandas DataFrame has, and then\n",
    "1.use code provided in your ChatBot session to print out the number of rows and columns of the dataset; and,\n",
    "2.write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71431e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de00536",
   "metadata": {},
   "source": [
    "\"observation\" refers to the different subjects recored in dataset, each row corresponds to one subject. The dataset above includes 391 observations, since it has 391 rows. \n",
    "\"variable\" refers to some detailed datas collected from observation, each column corresponds to one type of data. The dataset above includes 11 variables, since it has 11 column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aeda15",
   "metadata": {},
   "source": [
    "3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b918a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>admiral</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>bird</td>\n",
       "      <td>1-27</td>\n",
       "      <td>cranky</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>aye aye</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>agent-s</td>\n",
       "      <td>Agent S</td>\n",
       "      <td>female</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>7-2</td>\n",
       "      <td>peppy</td>\n",
       "      <td>DJ K.K.</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>villager-agent-s</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>agnes</td>\n",
       "      <td>Agnes</td>\n",
       "      <td>female</td>\n",
       "      <td>pig</td>\n",
       "      <td>4-21</td>\n",
       "      <td>uchi</td>\n",
       "      <td>K.K. House</td>\n",
       "      <td>snuffle</td>\n",
       "      <td>villager-agnes</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>al</td>\n",
       "      <td>Al</td>\n",
       "      <td>male</td>\n",
       "      <td>gorilla</td>\n",
       "      <td>10-18</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>Ayyeeee</td>\n",
       "      <td>villager-al</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>alfonso</td>\n",
       "      <td>Alfonso</td>\n",
       "      <td>male</td>\n",
       "      <td>alligator</td>\n",
       "      <td>6-9</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Forest Life</td>\n",
       "      <td>it'sa me</td>\n",
       "      <td>villager-alfonso</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>475</td>\n",
       "      <td>winnie</td>\n",
       "      <td>Winnie</td>\n",
       "      <td>female</td>\n",
       "      <td>horse</td>\n",
       "      <td>1-31</td>\n",
       "      <td>peppy</td>\n",
       "      <td>My Place</td>\n",
       "      <td>hay-OK</td>\n",
       "      <td>villager-winnie</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>477</td>\n",
       "      <td>wolfgang</td>\n",
       "      <td>Wolfgang</td>\n",
       "      <td>male</td>\n",
       "      <td>wolf</td>\n",
       "      <td>11-25</td>\n",
       "      <td>cranky</td>\n",
       "      <td>K.K. Song</td>\n",
       "      <td>snarrrl</td>\n",
       "      <td>villager-wolfgang</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>480</td>\n",
       "      <td>yuka</td>\n",
       "      <td>Yuka</td>\n",
       "      <td>female</td>\n",
       "      <td>koala</td>\n",
       "      <td>7-20</td>\n",
       "      <td>snooty</td>\n",
       "      <td>Soulful K.K.</td>\n",
       "      <td>tsk tsk</td>\n",
       "      <td>villager-yuka</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>481</td>\n",
       "      <td>zell</td>\n",
       "      <td>Zell</td>\n",
       "      <td>male</td>\n",
       "      <td>deer</td>\n",
       "      <td>6-7</td>\n",
       "      <td>smug</td>\n",
       "      <td>K.K. D&amp;B</td>\n",
       "      <td>pronk</td>\n",
       "      <td>villager-zell</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>483</td>\n",
       "      <td>zucker</td>\n",
       "      <td>Zucker</td>\n",
       "      <td>male</td>\n",
       "      <td>octopus</td>\n",
       "      <td>3-8</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Spring Blossoms</td>\n",
       "      <td>bloop</td>\n",
       "      <td>villager-zucker</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_n        id      name  gender    species birthday personality  \\\n",
       "0        2   admiral   Admiral    male       bird     1-27      cranky   \n",
       "1        3   agent-s   Agent S  female   squirrel      7-2       peppy   \n",
       "2        4     agnes     Agnes  female        pig     4-21        uchi   \n",
       "3        6        al        Al    male    gorilla    10-18        lazy   \n",
       "4        7   alfonso   Alfonso    male  alligator      6-9        lazy   \n",
       "..     ...       ...       ...     ...        ...      ...         ...   \n",
       "386    475    winnie    Winnie  female      horse     1-31       peppy   \n",
       "387    477  wolfgang  Wolfgang    male       wolf    11-25      cranky   \n",
       "388    480      yuka      Yuka  female      koala     7-20      snooty   \n",
       "389    481      zell      Zell    male       deer      6-7        smug   \n",
       "390    483    zucker    Zucker    male    octopus      3-8        lazy   \n",
       "\n",
       "                song    phrase            full_id  \\\n",
       "0         Steep Hill   aye aye   villager-admiral   \n",
       "1            DJ K.K.  sidekick   villager-agent-s   \n",
       "2         K.K. House   snuffle     villager-agnes   \n",
       "3         Steep Hill   Ayyeeee        villager-al   \n",
       "4        Forest Life  it'sa me   villager-alfonso   \n",
       "..               ...       ...                ...   \n",
       "386         My Place    hay-OK    villager-winnie   \n",
       "387        K.K. Song   snarrrl  villager-wolfgang   \n",
       "388     Soulful K.K.   tsk tsk      villager-yuka   \n",
       "389         K.K. D&B     pronk      villager-zell   \n",
       "390  Spring Blossoms     bloop    villager-zucker   \n",
       "\n",
       "                                                   url  \n",
       "0    https://villagerdb.com/images/villagers/thumb/...  \n",
       "1    https://villagerdb.com/images/villagers/thumb/...  \n",
       "2    https://villagerdb.com/images/villagers/thumb/...  \n",
       "3    https://villagerdb.com/images/villagers/thumb/...  \n",
       "4    https://villagerdb.com/images/villagers/thumb/...  \n",
       "..                                                 ...  \n",
       "386  https://villagerdb.com/images/villagers/thumb/...  \n",
       "387  https://villagerdb.com/images/villagers/thumb/...  \n",
       "388  https://villagerdb.com/images/villagers/thumb/...  \n",
       "389  https://villagerdb.com/images/villagers/thumb/...  \n",
       "390  https://villagerdb.com/images/villagers/thumb/...  \n",
       "\n",
       "[391 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa337fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefb6054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male      204\n",
       "female    187\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19305012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personality\n",
       "lazy      60\n",
       "normal    59\n",
       "cranky    55\n",
       "snooty    55\n",
       "jock      55\n",
       "peppy     49\n",
       "smug      34\n",
       "uchi      24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['personality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97402ca1",
   "metadata": {},
   "source": [
    "df.describe only summarize the numeric variable, so it is not accurate. Use df['column'].value_counts() to assist the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7734a0",
   "metadata": {},
   "source": [
    "4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by df.shape and what is reported by df.describe() with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c0023",
   "metadata": {},
   "source": [
    "1.df.shape gives that the data has 11 columns which includes non-numeric variables and numeric variables, while since df.describe only works for numeric column, de.describe() only summarize the \"row_n\" column. 2.If the dataset I used includes the missing value, the count reported by df.describe could be less than the real number of columns, since count only works for non-missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b3a15",
   "metadata": {},
   "source": [
    "5. Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference\n",
    "an \"attribute\", such as df.shape which does not end with ()\n",
    "and a \"method\", such as df.describe() which does end with ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9b6b3",
   "metadata": {},
   "source": [
    "An \"attribute\" is a default, which shows a nature or a characteristic of an object. You cannot operate attribute by adding any instructs in the parentheses. Contrast to an \"attribute\", a \"method\" can operate a calculation or computation. It represents an action that an object can perform, you can choose different objects by adding instruct in the parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4491a",
   "metadata": {},
   "source": [
    "6. The df.describe() method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5e9f2",
   "metadata": {},
   "source": [
    "count: Number of non-missing values for each column.\n",
    "mean: Average value of each column.\n",
    "std: Standard deviation, which measures the spread of the data.\n",
    "min: Minimum value in each column.\n",
    "25%, 50%, 75%: The 25th, 50th (median), and 75th percentiles.\n",
    "max: Maximum value in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184eccc9",
   "metadata": {},
   "source": [
    "7. Missing data can be considered \"across rows\" or \"down columns\". Consider how df.dropna() or del df['col'] should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words\n",
    "1.Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']\n",
    "\n",
    "\n",
    "2.Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna()\n",
    "\n",
    "\n",
    "3.Discuss why applying del df['col'] before df.dropna() when both are used together could be important\n",
    "\n",
    "\n",
    "4.Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c53d953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before using dropna():\n",
      " customer_id          0\n",
      "purchase_amount      2\n",
      "purchase_date        0\n",
      "customer_feedback    2\n",
      "coupon_used          2\n",
      "dtype: int64\n",
      "\n",
      "Shape of the dataset before using dropna(): (5, 5)\n",
      "\n",
      "Missing values after using dropna():\n",
      " customer_id          0\n",
      "purchase_amount      0\n",
      "purchase_date        0\n",
      "customer_feedback    0\n",
      "coupon_used          0\n",
      "dtype: int64\n",
      "\n",
      "Shape of the dataset after using dropna(): (1, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'purchase_amount': [100, None, 250, 300, None],\n",
    "    'purchase_date': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05'],\n",
    "    'customer_feedback': [None, 'Positive', None, 'Neutral', 'Negative'],\n",
    "    'coupon_used': ['Yes', None, 'No', 'Yes', None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check the number of missing values in each column before using dropna()\n",
    "missing_values_before = df.isna().sum()\n",
    "print(\"Missing values before using dropna():\\n\", missing_values_before)\n",
    "print(\"\\nShape of the dataset before using dropna():\", df.shape)\n",
    "# Use df.dropna() to remove rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Check the number of missing values after using dropna()\n",
    "missing_values_after = df_cleaned.isna().sum()\n",
    "print(\"\\nMissing values after using dropna():\\n\", missing_values_after)\n",
    "\n",
    "# Print the shape of the cleaned dataset\n",
    "print(\"\\nShape of the dataset after using dropna():\", df_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae23d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before deleting the column:\n",
      " customer_id           0\n",
      "age                   0\n",
      "gender                0\n",
      "income                0\n",
      "previous_purchases    0\n",
      "comments              2\n",
      "dtype: int64\n",
      "\n",
      "Shape of the dataset before deleting the column: (5, 6)\n",
      "\n",
      "Missing values after deleting the column:\n",
      " customer_id           0\n",
      "age                   0\n",
      "gender                0\n",
      "income                0\n",
      "previous_purchases    0\n",
      "dtype: int64\n",
      "\n",
      "Shape of the dataset after deleting the column: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'age': [25, 32, 40, 22, 30],\n",
    "    'gender': ['Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "    'income': [50000, 60000, 70000, 40000, 65000],\n",
    "    'previous_purchases': [3, 5, 2, 1, 4],\n",
    "    'comments': [None, 'Good service', None, 'Satisfied', 'Quick delivery']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check the number of missing values before removing the column\n",
    "missing_values_before = df.isna().sum()\n",
    "print(\"Missing values before deleting the column:\\n\", missing_values_before)\n",
    "print(\"\\nShape of the dataset before deleting the column:\", df.shape)\n",
    "\n",
    "# Use del to remove the 'comments' column\n",
    "del df['comments']\n",
    "\n",
    "# Check the number of missing values after removing the column\n",
    "missing_values_after = df.isna().sum()\n",
    "print(\"\\nMissing values after deleting the column:\\n\", missing_values_after)\n",
    "\n",
    "# Print the shape of the cleaned dataset\n",
    "print(\"\\nShape of the dataset after deleting the column:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe8759",
   "metadata": {},
   "source": [
    "3.Apply del df['col'] before df.dropna() when both are used together can aviod unnecessary dara loss. Using df.dropna() at first may result to delete some relevant datas, and make the summariztion inaccurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "570dc926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape of the dataset: (391, 11)\n",
      "\n",
      "Missing values before cleaning:\n",
      " row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n",
      "\n",
      "Shape of the dataset after cleaning: (390, 10)\n",
      "\n",
      "Missing values after cleaning:\n",
      " row_n          0\n",
      "id             0\n",
      "name           0\n",
      "gender         0\n",
      "species        0\n",
      "birthday       0\n",
      "personality    0\n",
      "phrase         0\n",
      "full_id        0\n",
      "url            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the initial shape and missing value counts\n",
    "print(\"Initial shape of the dataset:\", df.shape)\n",
    "print(\"\\nMissing values before cleaning:\\n\", df.isna().sum())\n",
    "\n",
    "# Step 1: Remove irrelevant columns with many missing values\n",
    "del df['song']  # example columns identified as irrelevant\n",
    "# Step 2: Drop rows with missing values in columns\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display the shape and missing value counts after cleaning\n",
    "print(\"\\nShape of the dataset after cleaning:\", df_cleaned.shape)\n",
    "print(\"\\nMissing values after cleaning:\\n\", df_cleaned.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2b066",
   "metadata": {},
   "source": [
    "Summaries of ChatBot session(s)：Session Summary\n",
    "Differences Between Attributes and Methods:\n",
    "\n",
    "Attributes (like df.shape) represent the properties or stored values of a DataFrame and do not require parentheses.\n",
    "Methods (like df.describe()) are functions associated with the DataFrame that perform specific actions or computations and require parentheses.\n",
    "Understanding the df.describe() Method:\n",
    "\n",
    "df.describe() provides summary statistics for numeric columns by default, including count, mean, standard deviation, min, max, and quartiles.\n",
    "It can also include non-numeric columns if you use df.describe(include='all').\n",
    "Handling Missing Data:\n",
    "\n",
    "Discussed the differences between df.dropna() and del df['col']:\n",
    "df.dropna(): Removes rows or columns containing missing values, allowing for the retention of as much useful data as possible.\n",
    "del df['col']: Deletes an entire column from the DataFrame, which can lead to loss of potentially valuable data.\n",
    "Provided a use case where df.dropna() is preferred over del df['col'] to efficiently use available non-missing data while preserving important columns.\n",
    "Overall, we explored how to utilize pandas methods and handle missing data to maintain data quality and maximize the use of available information.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70817ae5",
   "metadata": {},
   "source": [
    "link:https://chatgpt.com/share/0e8849fc-dda3-48fe-a803-94c67ade1ffd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e735ae",
   "metadata": {},
   "source": [
    "Results from the Code Execution:\n",
    "Before Cleaning:\n",
    "\n",
    "Initial Shape: (391, 19) (391 rows, 19 columns)\n",
    "Missing Values:\n",
    "house_rug: 391 missing values (entirely empty)\n",
    "catchphrase: 35 missing values\n",
    "Other columns with varying amounts of missing data.\n",
    "After Cleaning:\n",
    "\n",
    "Shape After Cleaning: (356, 17) (356 rows, 17 columns)\n",
    "Missing Values:\n",
    "All missing data from key columns (name, species, personality) has been removed.\n",
    "Irrelevant columns (house_rug and catchphrase) have been deleted.\n",
    "Summary of Functions:\n",
    "df.describe():\n",
    "\n",
    "Provides detailed statistical summaries for numerical columns.\n",
    "Requires parentheses () to invoke the method.\n",
    "df.shape:\n",
    "\n",
    "Provides the dimensions of the DataFrame (number of rows and columns).\n",
    "Accessed as an attribute without parentheses.\n",
    "By using these methods, we effectively cleaned the dataset and ensured that it is suitable for further analysis. This session emphasized the importance of handling missing data and understanding the structure of your dataset for meaningful insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c332b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eec9f5e9",
   "metadata": {},
   "source": [
    "8. Give brief explanations in your own words for any requested answers to the questions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a108df",
   "metadata": {},
   "source": [
    "1.Use your ChatBot session to understand what df.groupby(\"col1\")[\"col2\"].describe() does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a95e2dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "class                                                            \n",
      "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2c46978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8a4124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min        25%   50%    75%       max\n",
      "sex                                                                        \n",
      "female  314.0  44.479818  57.997698  6.75  12.071875  23.0  55.00  512.3292\n",
      "male    577.0  25.523893  43.138263  0.00   7.895800  10.5  26.55  512.3292\n"
     ]
    }
   ],
   "source": [
    "#different example\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = df.groupby(\"sex\")[\"fare\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7b140",
   "metadata": {},
   "source": [
    "2.Assuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have different values in the count value for different data columns depending on the missingness present in the original data. Why do these capture something fundamentally different from the values in the count that result from doing something like df.groupby(\"col1\")[\"col2\"].describe()?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0fc39",
   "metadata": {},
   "source": [
    "Because the count provided by df.describe() only alculate the non-missing value,and the missing values in different columns could be different, so the count value from df.groupby(\"col1\")[\"col2\"].describe() could be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdad59a",
   "metadata": {},
   "source": [
    "3.ntentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT\n",
    "A Forget to include import pandas as pd in your code\n",
    "Use Kernel->Restart from the notebook menu to restart the jupyter notebook session unload imported libraries and start over so you can create this error\n",
    "\n",
    "When python has an error, it sometimes provides a lot of \"stack trace\" output, but that's not usually very important for troubleshooting. For this problem for example, all you need to share with ChatGPT or search on google is \"NameError: name 'pd' is not defined\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0cd6c8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c32ef5",
   "metadata": {},
   "source": [
    "The NameError: name 'pd' is not defined error occurs when Python encounters a reference to pd, but it hasn't been properly defined or imported. This typically happens if the pandas library hasn't been imported with the alias pd, or if the import statement was accidentally omitted.\n",
    "\n",
    "To fix this error, make sure you import the pandas library at the beginning of your script or code. Here’s how you should do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7330028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a6d0c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "B:Mistype \"titanic.csv\" as \"titanics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a166fe2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read the dataset into a DataFrame\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitanics.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanics.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(\"titanics.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99b4f3",
   "metadata": {},
   "source": [
    "The FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv' error indicates that Python is trying to read a file named titanics.csv, but it cannot find this file in the specified directory.\n",
    "\n",
    "Given that you are trying to read data from a URL, it seems like there might be a mix-up with the file paths. Ensure that you are using the correct URL to read the dataset directly from the web.\n",
    "\n",
    "Here’s the corrected code snippet that reads from the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fcc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e48ba2",
   "metadata": {},
   "source": [
    "C:Try to use a dataframe before it's been assigned into the variable\n",
    "You can simulate this by just misnaming the variable. For example, if you should write df.groupby(\"col1\")[\"col2\"].describe() based on how you loaded the data, then instead write DF.groupby(\"col1\")[\"col2\"].describe()\n",
    "\n",
    "Make sure you've fixed your file name so that's not the error any more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c935c88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Group by the 'class' column and get descriptive statistics for the 'age' column\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m grouped_stats \u001b[38;5;241m=\u001b[39m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_stats)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = DF.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967db15b",
   "metadata": {},
   "source": [
    "The NameError: name 'DF' is not defined error occurs when Python encounters a reference to DF, but it hasn’t been defined or imported. This could be a typo or a case sensitivity issue, as Python is case-sensitive.\n",
    "\n",
    "In Python, df and DF are considered different variables due to case sensitivity. Ensure that you use the correct variable name consistently throughout your code.\n",
    "\n",
    "Here’s a corrected example with consistent use of df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfd67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Print the column names to check for the correct name\n",
    "print(df.columns)\n",
    "\n",
    "# Group by the correct column name and get descriptive statistics for 'age'\n",
    "grouped_stats = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747fc4a",
   "metadata": {},
   "source": [
    "D:Forget one of the parentheses somewhere the code\n",
    "For example, if the code should be pd.read_csv(url) the change it to pd.read_csv(url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c8d4ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2930201967.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv(url\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74da07",
   "metadata": {},
   "source": [
    "The SyntaxError: incomplete input typically occurs when there’s a mistake in the syntax, such as missing parentheses or incorrect indentation.\n",
    "\n",
    "In your case, it looks like the error is due to a missing closing parenthesis in the pd.read_csv() function call.\n",
    "\n",
    "Here's the corrected code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8094b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2178d03",
   "metadata": {},
   "source": [
    "E:Mistype one of the names of the chained functions with the code\n",
    "For example, try something like df.group_by(\"col1\")[\"col2\"].describe() and df.groupby(\"col1\")[\"col2\"].describle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4667fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'describle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Group by the 'class' column and get descriptive statistics for the 'age' column\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m grouped_stats \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescrible\u001b[49m()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_stats)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1312\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m-> 1312\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1314\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'describle'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = df.groupby(\"class\")[\"age\"].describle()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d53946b",
   "metadata": {},
   "source": [
    "The AttributeError: 'SeriesGroupBy' object has no attribute 'describle' error is due to a typo in the method name. The correct method name is describe, not describle.\n",
    "\n",
    "Here’s the corrected code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d62cdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "class                                                            \n",
      "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a96d8",
   "metadata": {},
   "source": [
    "F:Use a column name that's not in your data for the groupby and column selection\n",
    "For example, try capitalizing the columns for example replacing \"sex\" with \"Sex\" in titanic_df.groupby(\"sex\")[\"age\"].describe(), and then instead introducing the same error of \"age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82dfcb9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Group by the 'class' column and get descriptive statistics for the 'age' column\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m grouped_stats \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_stats)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Class'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = df.groupby(\"Class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144896f",
   "metadata": {},
   "source": [
    "The KeyError: 'Class' suggests that you are trying to access a column named 'Class', but it doesn’t exist in your DataFrame. Column names are case-sensitive in pandas, so 'Class' and 'class' are treated as different columns.\n",
    "\n",
    "To resolve this issue, follow these steps:\n",
    "\n",
    "Check Column Names: Verify the exact column names in your DataFrame to ensure you’re using the correct name.\n",
    "\n",
    "Use the Correct Column Name: Update your code to use the correct column name as shown in your DataFrame.\n",
    "\n",
    "Here’s how to check the column names and adjust your code accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Print the column names to find the correct name\n",
    "print(df.columns)\n",
    "\n",
    "# Correctly group by the existing column name and get descriptive statistics for 'age'\n",
    "# Assuming the correct column name is 'class'\n",
    "grouped_stats = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a5b96",
   "metadata": {},
   "source": [
    "G:Forget to put the column name as a string in quotes for the groupby and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "For example, something like titanic_df.groupby(sex)[\"age\"].describe(), and then titanic_df.groupby(\"sex\")[age].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fbaf486",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (295829936.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    grouped_stats = df.groupby(class)[\"age\"].describe()\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Print the column names to find the correct name\n",
    "print(df.columns)\n",
    "\n",
    "# Correctly group by the existing column name and get descriptive statistics for 'age'\n",
    "# Assuming the correct column name is 'class'\n",
    "grouped_stats = df.groupby(class)[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0437d",
   "metadata": {},
   "source": [
    "The SyntaxError: invalid syntax error in this context is likely due to not properly quoting the column name in the groupby method. Column names should be passed as strings in quotes.\n",
    "\n",
    "Here’s the corrected code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Print the column names to verify\n",
    "print(df.columns)\n",
    "\n",
    "# Group by the 'class' column and get descriptive statistics for the 'age' column\n",
    "grouped_stats = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b33a0",
   "metadata": {},
   "source": [
    "Summaries of ChatBot session(s)：https://chatgpt.com/share/24370692-fac7-4cf5-8759-688e7679dfb7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b4d1a",
   "metadata": {},
   "source": [
    "9Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3898775",
   "metadata": {},
   "source": [
    "Somewhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
